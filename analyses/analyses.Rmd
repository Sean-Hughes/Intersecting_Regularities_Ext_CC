---
title: "IR, extinction, & counter conditioning"
subtitle: "Analyses & meta-analyses"
author: "Ian Hussey & Sean Hughes"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes 
    toc_float: yes
---

```{r include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE)
```

.libPaths()


# Dependencies & functions

```{r}

# dependencies -----
library(tidyverse)
library(ggthemes)
library(knitr)
library(kableExtra)
library(broom)
library(effsize)
library(BayesFactor)
library(metafor)
library(ez)
library(schoRsch)
library(nnet)
library(epitools)

options(knitr.kable.NA = "/") 

# Ensures that the processed data folder exists
dir.create("models")
dir.create("results")

# functions -----
# round p value using apa format
apa_p_value <- function(p){
  p_formatted <- ifelse(p >= 0.0001, paste("=", round(p, 4)),
                        ifelse(p < 0.0001, "< .0001", NA))
  p_formatted <- gsub(pattern = "0.", replacement = ".", x = p_formatted, fixed = TRUE)
  p_formatted
}

# calculate cohens d and return its output in tidy format - a helper function for analysis_workflow
tidy_cohens_d <- function(data){
  require(effsize)
  
  fit <- effsize::cohen.d(DV ~ IV, data = data)
  
  results <- tibble(cohens_d = fit$estimate,
                    cohens_d_ci_lower = fit$conf.int["lower"],
                    cohens_d_ci_upper = fit$conf.int["upper"])
  
  return(results)
}

# calculate cohens d and return its output in tidy format - a helper function for analysis_workflow
tidy_ttest_bf <- function(data){
  require(BayesFactor)
  
  fit <- data %>%
    ttestBF(formula = DV ~ IV, data = .)

  results <- data.frame(bf10 = extractBF(fit)$bf)
  return(results)
}


# full analysis workflow
# NB workflow returns mean_reference and mean_comparison, where reference is the first factor level and comparison is the next highest level.
analysis_workflow <- function(data){
  
  # frequentist t test
  results_t_test <- data %>%
    group_by(experiment, DV_type) %>%
    do(broom::tidy(t.test(DV ~ IV, data = .))) %>%
    ungroup() %>%
    rename(t = statistic,
           df = parameter,
           p = p.value,
           mean_reference = estimate1,
           mean_comaprison = estimate2)

  # cohens d
  results_cohens_d <- data %>%
    group_by(experiment, DV_type) %>%
    do(tidy_cohens_d(data = .)) %>%
    ungroup()
  
  # BF t test
  results_bf_t_test <- data %>%
    group_by(experiment, DV_type) %>%
    do(tidy_ttest_bf(data = .)) %>%
    ungroup()
  
  # combine
  results <- 
    full_join(results_t_test,
              results_cohens_d,
              by = c("experiment", "DV_type")) %>%
    full_join(results_bf_t_test,
              by = c("experiment", "DV_type")) %>%
    select(experiment, DV_type, 
           mean_reference, mean_comaprison, 
           t, df, p, cohens_d, cohens_d_ci_lower, cohens_d_ci_upper, bf10) %>%
    mutate(reportable_result = paste0("Reference group M = ", round(mean_reference, 2), ", comparison group M = ", round(mean_comaprison, 2), ", t(", round(df, 2), ") = ", round(t, 2), ", p ", apa_p_value(p), ", d = ", round(cohens_d, 2), ", 95% CI [", round(cohens_d_ci_lower, 2), ", ", round(cohens_d_ci_upper, 2), "], BF10 = ", round(bf10, 1)))
  
  return(results)
}

# add heterogeneity stats string for forest plot
add_heterogeneity_metrics_to_forest <- function(fit) {
  bquote(paste("RE Model (", tau^2, " = ", .(formatC(round(fit$tau2, 1))), 
               ", ", I^2, " = ", .(formatC(round(fit$I2, 1))),
               "%, ", H^2," = ", .(formatC(round(fit$H2, 1))), ")"))
}

```

# Data and exclusions

```{r}

# full data
data_processed <-
  bind_rows(
    read_csv("../data/Study 1/processed/data_processed.csv"),
    read_csv("../data/Study 2/processed/data_processed.csv"),
    read_csv("../data/Study 3/processed/data_processed.csv"),
    read_csv("../data/Study 4/processed/data_processed.csv"),
    read_csv("../data/Study 5/processed/data_processed.csv"),
    read_csv("../data/Study 6/processed/data_processed.csv"),
    read_csv("../data/Study 7/processed/data_processed.csv")
  ) %>%
  # set factor levels for t test comparisons
  mutate(experiment_condition = fct_relevel(experiment_condition,
                                            "acquisition_only", 
                                            "acquisition_and_extinction",
                                            "acquisition_and_counterconditioning"),
         stimulus_identity_condition = fct_relevel(stimulus_identity_condition,
                                                   "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad",
                                                   "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good")) %>%
  mutate(exclude = ifelse(completeness_acquisition_training == "complete" &
                            completeness_acquisition_testing == "complete" &
                            (completeness_extinction_training == "complete" | 
                               is.na(completeness_extinction_training)) &
                            (completeness_extinction_testing == "complete" | 
                               is.na(completeness_extinction_testing)) &
                            (completeness_counterconditioning_training == "complete" |
                               is.na(completeness_counterconditioning_training)) &
                            (completeness_counterconditioning_testing == "complete" |
                               is.na(completeness_counterconditioning_testing)) &
                            complete_iat_data == "complete" &
                            passed_iat_performance == TRUE,
                          FALSE, TRUE)) %>%
  
  ## move this to data processing??
  
  mutate(
    # recoding for the IR intentions data
    behavioral_intentions_IR = case_when(
      as.character(behavioral_intentions_IR) == "I would try Brand 2" ~ "brand_A",
      as.character(behavioral_intentions_IR) == "I would try Brand 4" ~ "brand_B",
      as.character(behavioral_intentions_IR) == "I would try Brands 2 and 4" ~ "both",
      as.character(behavioral_intentions_IR) == "I would try neither Brand" ~ "neither",
      as.character(behavioral_intentions_IR) == "I don't know" ~ "idontknow",
      TRUE ~ as.character(behavioral_intentions_IR)
    ),
    # recoding for the OEC intentions data
    behavioral_intentions_OEC = case_when(
      as.character(behavioral_intentions_OEC) == "I would try Brand 1" ~ "brand_A",
      as.character(behavioral_intentions_OEC) == "I would try Brand 3" ~ "brand_B",
      as.character(behavioral_intentions_OEC) == "I would try Brands 1 and 3" ~ "both",
      as.character(behavioral_intentions_OEC) == "I would try neither Brand" ~ "neither",
      as.character(behavioral_intentions_OEC) == "I don't know" ~ "idontknow",
      TRUE ~ as.character(behavioral_intentions_OEC)
    ),
    # reverse score
    behavioral_intentions_IR_controlling_stimulus_identity = case_when(
      stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" & 
        as.character(behavioral_intentions_IR) == "brand_A" ~ "brand_B",
      stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" & 
        as.character(behavioral_intentions_IR) == "brand_A" ~ "brand_A",
      stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" & 
        as.character(behavioral_intentions_IR) == "brand_B" ~ "brand_A",
      stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" & 
        as.character(behavioral_intentions_IR) == "brand_B" ~ "brand_B",
      TRUE ~ as.character(behavioral_intentions_IR)
    ),
    behavioral_intentions_OEC_controlling_stimulus_identity = case_when(
      stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" & 
        as.character(behavioral_intentions_OEC) == "brand_A" ~ "brand_B",
      stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" & 
        as.character(behavioral_intentions_OEC) == "brand_A" ~ "brand_A",
      stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" & 
        as.character(behavioral_intentions_OEC) == "brand_B" ~ "brand_A",
      stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" & 
        as.character(behavioral_intentions_OEC) == "brand_B" ~ "brand_B",
      TRUE ~ as.character(behavioral_intentions_OEC)
    )
  ) 

# exclusions
data_processed_after_exclusions <- data_processed %>%
  filter(exclude == FALSE)

```

# Demographics

, na.rm = TRUE shouldn't be needed, check data processing

why are there 49 participants in an unknown experiment?

```{r}

data_processed %>%
  group_by(experiment) %>%
  summarize(n = n(),
            age_mean = mean(age, na.rm = TRUE),
            age_sd = mean(age, na.rm = TRUE),
            excluded_n = sum(exclude, na.rm = TRUE),
            excluded_percent = mean(exclude*100, na.rm = TRUE)) %>%
  mutate_if(is.numeric, round, digits = 1)

```

# Training and testing mastery

## Percentage accuracy

```{r fig.height=10, fig.width=7}

results_training_and_testing_percent_accuracy <- data_processed_after_exclusions %>% 
  select(unique_id, experiment, 
         mean_correct_acquisition_training,         mean_correct_acquisition_testing, 
         mean_correct_extinction_training,          mean_correct_extinction_testing, 
         mean_correct_counterconditioning_training, mean_correct_counterconditioning_testing) %>%
  gather(phase, mean_correct, c(mean_correct_acquisition_training, mean_correct_acquisition_testing, 
                                mean_correct_extinction_training, mean_correct_extinction_testing, 
                                mean_correct_counterconditioning_training, mean_correct_counterconditioning_testing)) %>%
  distinct(unique_id, phase, .keep_all = TRUE) %>%
  drop_na() %>%
  mutate(phase = dplyr::recode(phase, 
                               "mean_correct_acquisition_training" = "Acquisition\ntraining",
                               "mean_correct_acquisition_testing" = "Acquisition\ntest",
                               "mean_correct_extinction_training" = "Extinction\ntraining",
                               "mean_correct_extinction_testing" = "Extinction\ntesting",
                               "mean_correct_counterconditioning_training" = "Counterconditioning\ntraining",
                               "mean_correct_counterconditioning_testing" = "Counterconditioning\ntesting")) %>%
  mutate(phase = as.factor(phase)) %>% 
  mutate(phase = fct_relevel(phase, "Acquisition\ntraining",
                                    "Acquisition\ntest",
                                    "Extinction\ntraining",
                                    "Extinction\ntesting",
                                    "Counterconditioning\ntraining",
                                    "Counterconditioning\ntesting")) %>%
  
  group_by(experiment, phase) %>% 
  dplyr::summarise(mean_accuracy = mean(mean_correct*100, na.rm = TRUE), 
                   sd_accuracy = sd(mean_correct*100, na.rm = TRUE)) %>%
  ungroup()

results_training_and_testing_percent_accuracy %>%
  mutate_if(is.numeric, round, digits = 0) %>%
  mutate(result = paste0(mean_accuracy, " (", sd_accuracy, ")")) %>%
  select(-mean_accuracy, -sd_accuracy) %>%
  spread(phase, result) %>%
  kable(align = "c") %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) 
  
# ggplot(results_training_and_testing_percent_accuracy, aes(x = phase, y = mean_accuracy)) +
#   geom_bar(colour = "black", stat = "identity") + 
#   geom_errorbar(aes(ymin = mean_accuracy - sd_accuracy, ymax = mean_accuracy + sd_accuracy), 
#                 width = .2) + 
#   theme_classic() +
#   facet_wrap(~experiment, ncol = 1)

```

## Percentage pass

```{r fig.height=10, fig.width=7}

results_training_and_testing_percent_pass <- data_processed_after_exclusions %>% 
  select(unique_id, experiment, 
         passed_performance_criterion_acquisition_training,         passed_performance_criterion_acquisition_testing, 
         passed_performance_criterion_extinction_training,          passed_performance_criterion_extinction_testing, 
         passed_performance_criterion_counterconditioning_training, passed_performance_criterion_counterconditioning_testing) %>%
  gather(phase, passed_performance_criterion, c(passed_performance_criterion_acquisition_training,
                                                passed_performance_criterion_acquisition_testing, 
                                                passed_performance_criterion_extinction_training,
                                                passed_performance_criterion_extinction_testing, 
                                                passed_performance_criterion_counterconditioning_training,
                                                passed_performance_criterion_counterconditioning_testing)) %>%
  distinct(unique_id, phase, .keep_all = TRUE) %>%
  drop_na() %>%
  mutate(phase = dplyr::recode(phase, 
                            "passed_performance_criterion_acquisition_training" = "Acquisition\ntraining",
                            "passed_performance_criterion_acquisition_testing" = "Acquisition\ntest",
                            "passed_performance_criterion_extinction_training" = "Extinction\ntraining",
                            "passed_performance_criterion_extinction_testing" = "Extinction\ntesting",
                            "passed_performance_criterion_counterconditioning_training" = "Counterconditioning\ntraining",
                            "passed_performance_criterion_counterconditioning_testing" = "Counterconditioning\ntesting")) %>%
  
  mutate(phase = as.factor(phase)) %>% 
  mutate(phase = fct_relevel(phase, "Acquisition\ntraining",
                                    "Acquisition\ntest",
                                    "Extinction\ntraining",
                                    "Extinction\ntesting",
                                    "Counterconditioning\ntraining",
                                    "Counterconditioning\ntesting")) %>%
  
  
  
  group_by(experiment, phase) %>% 
  dplyr::summarise(percent_passed = mean(passed_performance_criterion*100, na.rm = TRUE)) %>%
  ungroup()

results_training_and_testing_percent_pass %>%
  mutate_if(is.numeric, round, digits = 0) %>%
  spread(phase, percent_passed) %>%
  kable(align = "c") %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  
```

# Analyses by study

## Was there an IR effect?

### IAT & self_reports

- by DV
- Differences between stimulus identity, using only the acquisition_only condition.

```{r}

results_basic_effect_iat_selfreports <- data_processed_after_exclusions %>%
  filter(experiment_condition == "acquisition_only") %>%
  rename(IV = stimulus_identity_condition) %>%
  gather(DV_type, DV, c(self_reported_OEC_effect, self_reported_IR_effect, IAT_D2)) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  analysis_workflow(data = .)

write_csv(results_basic_effect_iat_selfreports, "results/results_basic_effect_iat_selfreports.csv")

results_basic_effect_iat_selfreports %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)


# In earlier analyses the following basic effects came out: * indicates deviation from current results
# Exp 1:
#   IR  present (p < .001) *
#   OEC present (p < .001) 
#   IAT present (p < .001)

# Exp 2:
#   IR  present (p < .001)
#   OEC present (p < .001) 
#   IAT present (p = .78) 

# Exp 3:
#   IR  present (p < .001)
#   OEC present (p < .001) 
#   IAT present (p < .001)

# Exp 4:
#   IR  present (p < .001)
#   OEC present (p < .001) 
#   IAT present (p = .024)

# Exp 5:
#   IR  present (p = .10) *
#   OEC present (p = .02) 
#   IAT present (p = .45) *

# Exp 6:
#   IR  present (p < .001)
#   OEC present (p < .001) 
#   IAT present (p = .23) *

# Exp 7:
#   IR  present (p = .005)
#   OEC present (p < .001) 
#   IAT present (p = .33) *

```

### Behavioral intentions

NB Haldane-Anscombe correction applied to studies where at least one cell contained zero/NA counts, in which case 1 was added to all cells. 

```{r}

data_reshaped_intentions_acquisition_ir <- data_processed_after_exclusions %>%
  filter(experiment_condition == c("acquisition_only") & 
           behavioral_intentions_IR %in% c("brand_A", "brand_B")) %>% 
  count(experiment, stimulus_identity_condition, behavioral_intentions_IR) %>%
  spread(behavioral_intentions_IR, n) %>%
  # Haldane-Anscombe correction
  group_by(experiment) %>%
  mutate(count_zero = as.logical(max(c(is.na(brand_A), is.na(brand_B))))) %>%
  ungroup() %>%
  mutate(brand_A = ifelse(count_zero, brand_A+1, brand_A),
         brand_A = ifelse(is.na(brand_A), 1, brand_A),
         brand_B = ifelse(count_zero, brand_B+1, brand_B),
         brand_B = ifelse(is.na(brand_B), 1, brand_B)) %>%
  select(experiment, stimulus_identity_condition, brand_A, brand_B)

temp_study_1 <- data_reshaped_intentions_acquisition_ir %>%
  filter(experiment == 1) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_2 <- data_reshaped_intentions_acquisition_ir %>%
  filter(experiment == 2) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_3 <- data_reshaped_intentions_acquisition_ir %>%
  filter(experiment == 3) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_4 <- data_reshaped_intentions_acquisition_ir %>%
  filter(experiment == 4) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_5 <- data_reshaped_intentions_acquisition_ir %>%
  filter(experiment == 5) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_6 <- data_reshaped_intentions_acquisition_ir %>%
  filter(experiment == 6) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_7 <- data_reshaped_intentions_acquisition_ir %>%
  filter(experiment == 7) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

results_basic_effect_intentions_ir <- 
  bind_rows(
    as.data.frame(temp_study_1$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 1),
    as.data.frame(temp_study_2$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 2),
    as.data.frame(temp_study_3$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 3),
    as.data.frame(temp_study_4$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 4),
    as.data.frame(temp_study_5$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 5),
    as.data.frame(temp_study_6$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 6),
    as.data.frame(temp_study_7$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 7)
  ) %>%
  select(experiment, OR, OR_ci_lower, OR_ci_upper, p) %>%
  mutate(OR = round(OR, 2),
         OR_ci_lower = round(OR_ci_lower, 2),
         OR_ci_upper = round(OR_ci_upper, 2))

write_csv(results_basic_effect_intentions_ir, "results/results_basic_effect_intentions_ir.csv")

results_basic_effect_intentions_ir %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)



# In earlier analyses the following basic effects came out: * indicates deviation from current results
# Exp 1:
#   IR  present (p = .004) *

# Exp 2:
#   IR  present (p < .001)

# Exp 3:
#   IR  present (p = .005)

# Exp 4:
#   IR  present (p = .05)

# Exp 5:
#   IR  present (p = .001) 

# Exp 6:
#   IR  present (p = .144)

# Exp 7:
#   IR  present (p = .52)


```


## Was the IR moderated by extinction?

### IAT & self_reports

- by DV
- Differences between experiment conditions, after reverse scoring for stimulus identity.

```{r}

results_moderation_by_extinction <- data_processed_after_exclusions %>%
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_extinction") & 
           experiment %in% c(1, 2, 3, 4, 7)) %>%
  rename(IV = experiment_condition) %>%
  mutate(IV = fct_relevel(IV, "acquisition_and_extinction", "acquisition_only")) %>%
  gather(DV_type, DV, c(self_reported_OEC_effect_controlling_stimulus_identity, 
                        self_reported_IR_effect_controlling_stimulus_identity, 
                        IAT_D2_controlling_stimulus_identity)) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  analysis_workflow(data = .)

write_csv(results_moderation_by_extinction, "results/results_moderation_by_extinction.csv")

results_moderation_by_extinction %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# In earlier analyses the following moderation effects came out: * indicates deviation from current results
# Exp 1:
#   IR  present (p = .19) 
#   OEC present (p = .41) 
#   IAT present (p = .61)

# Exp 2:
#   IR  present (p = .009)
#   OEC present (p < .001) 
#   IAT present (p = .85) 

# Exp 3:
#   IR  present (p = .04)  *
#   OEC present (p < .001) 
#   IAT present (p < .001) *

# Exp 4:
#   IR  present (p = .63)
#   OEC present (p = .22) 
#   IAT present (p = .81)

# Exp 5:
#   IR  present (p = .002) 
#   OEC present (p < .001) 
#   IAT present (p = .63) 

# Exp 6:
#   IR  present (p = .59)
#   OEC present (p = .01) 
#   IAT present (p = .82) 

# Exp 7:
#   IR  present (p < .001) *
#   OEC present (p = .12) 
#   IAT present (p = .72) 

```

### Behavioral intentions

```{r}

data_reshaped_intentions_moderation_by_extinction_ir <- data_processed_after_exclusions %>%
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_extinction") & 
           experiment %in% c(1, 2, 3, 4, 7) & 
           behavioral_intentions_IR %in% c("brand_A", "brand_B")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_IR) %>%
  spread(behavioral_intentions_IR, n) %>%
  # Haldane-Anscombe correction
  group_by(experiment) %>%
  mutate(count_zero = as.logical(max(c(is.na(brand_A), is.na(brand_B))))) %>%
  ungroup() %>%
  mutate(brand_A = ifelse(count_zero, brand_A+1, brand_A),
         brand_A = ifelse(is.na(brand_A), 1, brand_A),
         brand_B = ifelse(count_zero, brand_B+1, brand_B),
         brand_B = ifelse(is.na(brand_B), 1, brand_B)) %>%
  select(experiment, experiment_condition, brand_A, brand_B)

temp_study_1 <- data_reshaped_intentions_moderation_by_extinction_ir %>%
  filter(experiment == 1) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_2 <- data_reshaped_intentions_moderation_by_extinction_ir %>%
  filter(experiment == 2) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_3 <- data_reshaped_intentions_moderation_by_extinction_ir %>%
  filter(experiment == 3) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_4 <- data_reshaped_intentions_moderation_by_extinction_ir %>%
  filter(experiment == 4) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_7 <- data_reshaped_intentions_moderation_by_extinction_ir %>%
  filter(experiment == 7) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

results_moderation_by_extinction_intentions_ir <- 
  bind_rows(
    as.data.frame(temp_study_1$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 1),
    as.data.frame(temp_study_2$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 2),
    as.data.frame(temp_study_3$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 3),
    as.data.frame(temp_study_4$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 4),
    as.data.frame(temp_study_7$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 7)
  ) %>%
  select(experiment, OR, OR_ci_lower, OR_ci_upper, p) %>%
  mutate(OR = round(OR, 2),
         OR_ci_lower = round(OR_ci_lower, 2),
         OR_ci_upper = round(OR_ci_upper, 2))

write_csv(results_moderation_by_extinction_intentions_ir, "results/results_moderation_by_extinction_intentions_ir.csv")

results_moderation_by_extinction_intentions_ir %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Was the IR moderated by counter conditioning?

### IAT & self_reports

- by DV
- Differences between experiment conditions, after reverse scoring for stimulus identity.

```{r}

results_moderation_by_counterconditioning <- data_processed_after_exclusions %>%
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_counterconditioning") & 
           experiment %in% c(5, 6, 7)) %>%
  rename(IV = experiment_condition) %>%
  mutate(IV = fct_relevel(IV, "acquisition_and_counterconditioning", "acquisition_only")) %>%
  gather(DV_type, DV, c(self_reported_OEC_effect_controlling_stimulus_identity, 
                        self_reported_IR_effect_controlling_stimulus_identity, 
                        IAT_D2_controlling_stimulus_identity)) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  analysis_workflow(data = .)

write_csv(results_moderation_by_counterconditioning, "results/results_moderation_by_counterconditioning.csv")

results_moderation_by_counterconditioning %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

### Behavioral intentions

```{r}

data_reshaped_intentions_moderation_by_counterconditioning_ir <- data_processed_after_exclusions %>%
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_counterconditioning") & 
           experiment %in% c(5, 6, 7) & 
           behavioral_intentions_IR %in% c("brand_A", "brand_B")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_IR) %>%
  spread(behavioral_intentions_IR, n) %>%
  # Haldane-Anscombe correction
  group_by(experiment) %>%
  mutate(count_zero = as.logical(max(c(is.na(brand_A), is.na(brand_B))))) %>%
  ungroup() %>%
  mutate(brand_A = ifelse(count_zero, brand_A+1, brand_A),
         brand_A = ifelse(is.na(brand_A), 1, brand_A),
         brand_B = ifelse(count_zero, brand_B+1, brand_B),
         brand_B = ifelse(is.na(brand_B), 1, brand_B)) %>%
  select(experiment, experiment_condition, brand_A, brand_B)

temp_study_5 <- data_reshaped_intentions_moderation_by_counterconditioning_ir %>%
  filter(experiment == 5) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_6 <- data_reshaped_intentions_moderation_by_counterconditioning_ir %>%
  filter(experiment == 6) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_7 <- data_reshaped_intentions_moderation_by_counterconditioning_ir %>%
  filter(experiment == 7) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

results_moderation_by_counterconditioning_intentions_ir <- 
  bind_rows(
    as.data.frame(temp_study_5$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 5),
    as.data.frame(temp_study_6$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 6),
    as.data.frame(temp_study_7$tab) %>%
      drop_na() %>%
      select(OR = oddsratio, OR_ci_lower = lower, OR_ci_upper = upper, p = p.value) %>%
      mutate(experiment = 7)
  ) %>%
  select(experiment, OR, OR_ci_lower, OR_ci_upper, p) %>%
  mutate(OR = round(OR, 2),
         OR_ci_lower = round(OR_ci_lower, 2),
         OR_ci_upper = round(OR_ci_upper, 2))

write_csv(results_moderation_by_counterconditioning_intentions_ir,
          "results/results_moderation_by_counterconditioning_intentions_ir.csv")

results_moderation_by_counterconditioning_intentions_ir %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Study 7 ANOVA

drop_na SHOULDN'T BE NEEDED ??

```{r}

data_study_7 <- data_processed_after_exclusions %>%
  filter(experiment == 7) %>%
  select(unique_id,
         self_reported_IR_effect_controlling_stimulus_identity,
         self_reported_OEC_effect_controlling_stimulus_identity,
         IAT_D2_controlling_stimulus_identity,
         experiment_condition) %>%
  drop_na()

# IAT
fit_study_7_iat <- ez::ezANOVA(data     = data_study_7,
                               dv       = IAT_D2_controlling_stimulus_identity,
                               between  = experiment_condition,
                               wid      = unique_id,
                               type     = 3,
                               detailed = TRUE)

 
  
# IR
fit_study_7_ir <- ez::ezANOVA(data     = data_study_7,
                              dv       = self_reported_IR_effect_controlling_stimulus_identity,
                              between  = experiment_condition,
                              wid      = unique_id,
                              type     = 3,
                              detailed = TRUE)

# OEC
fit_study_7_oec <- ez::ezANOVA(data     = data_study_7,
                               dv       = self_reported_OEC_effect_controlling_stimulus_identity,
                               between  = experiment_condition,
                               wid      = unique_id,
                               type     = 3,
                               detailed = TRUE)

# combine results
results_study_7 <- 
  bind_rows(anova_out(fit_study_7_iat, 
                      etasq = "partial", 
                      print = FALSE)$`--- FORMATTED RESULTS ------------------------------------` %>%
              mutate(DV = "IAT"),
            anova_out(fit_study_7_ir, 
                      etasq = "partial", 
                      print = FALSE)$`--- FORMATTED RESULTS ------------------------------------` %>%
              mutate(DV = "IR"),
            anova_out(fit_study_7_oec, 
                      etasq = "partial", 
                      print = FALSE)$`--- FORMATTED RESULTS ------------------------------------` %>%
              mutate(DV = "OEC")) %>%
  filter(Effect == "experiment_condition") %>%
  select(DV, Text)

results_study_7 %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Meta-analyses

## Basic effect

### IAT & self_reports

```{r}

results_for_meta_basic_effect_iat_selfreports <- results_basic_effect_iat_selfreports %>%
  rename(yi = cohens_d) %>%
  mutate(sei = (cohens_d_ci_upper - cohens_d_ci_lower)/(2*1.96)) %>%
  select(experiment, DV_type, yi, sei)

# iat
fit_basic_effect_iat <- results_for_meta_basic_effect_iat_selfreports %>%
  filter(str_detect(DV_type, "IAT_D2")) %>%
  rma(yi   = yi,
      sei  = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_iat,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-1.5, 4),
                at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
text(-1.5, 9, "IR effect (IAT)", pos = 4)
text(4, 9, "d [95% CI]", pos = 2)

# IR
fit_basic_effect_ir <- results_for_meta_basic_effect_iat_selfreports %>%
  filter(str_detect(DV_type, "_IR_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_ir,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-1.5, 4),
                at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
text(-1.5, 9, "IR effect (self-reported evaluations)", pos = 4)
text(4, 9, "d [95% CI]", pos = 2)

# OEC
fit_basic_effect_oec <- results_for_meta_basic_effect_iat_selfreports %>%
  filter(str_detect(DV_type, "_OEC_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_oec,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-1.5, 4),
                at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
text(-1.5, 9, "OEC effect (self-reported evaluations)", pos = 4)
text(4, 9, "d [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_basic_effect_iat, "models/fit_basic_effect_iat.rds")
write_rds(fit_basic_effect_ir, "models/fit_basic_effect_ir.rds")
write_rds(fit_basic_effect_oec, "models/fit_basic_effect_oec.rds")

```

### Behavioral intentions

```{r}

fit_basic_effect_intentions_ir <- data_reshaped_intentions_acquisition_ir %>%
  pivot_wider(names_from = stimulus_identity_condition,
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad,
         bi = brand_B_Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad,
         ci = brand_A_Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good,
         di = brand_B_Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_intentions_ir,
                addcred = TRUE,
                refline = 0,
                xlim = c(-5, 12),
                at = c(-2, 0, 2, 4, 6, 8))
text(-5, 9, "IR effect (behavioral intentions)", pos = 4)
text(12, 9, "OR [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_basic_effect_intentions_ir, "models/fit_basic_effect_intentions_ir.rds")

```

## Moderation by extinction

### IAT & self_reports

```{r}

results_for_meta_extinction <- results_moderation_by_extinction %>%
  rename(yi = cohens_d) %>%
  mutate(sei = (cohens_d_ci_upper - cohens_d_ci_lower)/(2*1.96)) %>%
  select(experiment, DV_type, yi, sei)

# iat
fit_moderation_extinction_iat <- results_for_meta_extinction %>%
  filter(str_detect(DV_type, "IAT_D2")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_iat,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-2.25, 2.25),
                at = c(-1.5, -1.0, -0.5, 0, 0.5, 1.0))
text(-2.25, 7, "Moderation of IR by extinction (IAT)", pos = 4)
text(2.25, 7, "d [95% CI]", pos = 2)

# IR
fit_moderation_extinction_ir <- results_for_meta_extinction %>%
  filter(str_detect(DV_type, "_IR_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_ir,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-2.25, 2.25),
                at = c(-1.5, -1.0, -0.5, 0, 0.5, 1.0))
text(-2.25, 7, "Moderation of IR by extinction (self-reported evaluations)", pos = 4)
text(2.25, 7, "d [95% CI]", pos = 2)

# OEC
fit_moderation_extinction_oec <- results_for_meta_extinction %>%
  filter(str_detect(DV_type, "_OEC_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_oec,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-2.25, 2.25),
                at = c(-1.5, -1.0, -0.5, 0, 0.5, 1.0))
text(-2.25, 7, "Moderation of OEC by extinction (self-reported evaluations)", pos = 4)
text(2.25, 7, "d [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_moderation_extinction_iat, "models/fit_moderation_extinction_iat.rds")
write_rds(fit_moderation_extinction_ir, "models/fit_moderation_extinction_ir.rds")
write_rds(fit_moderation_extinction_oec, "models/fit_moderation_extinction_oec.rds")

```

### Behavioral intentions

```{r}

fit_moderation_extinction_ir <- data_reshaped_intentions_moderation_by_extinction_ir %>%
  pivot_wider(names_from = experiment_condition,
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_acquisition_only,
         bi = brand_B_acquisition_only,
         ci = brand_A_acquisition_and_extinction,
         di = brand_B_acquisition_and_extinction,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_ir,
                addcred = TRUE,
                refline = 0,
                xlim = c(-5, 12),
                at = c(-2, 0, 2, 4, 6, 8))
text(-5, 7, "Moderation of IR by extinction (behavioral intentions)", pos = 4)
text(12, 7, "OR [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_moderation_extinction_ir, "models/fit_moderation_extinction_ir.rds")

```

## Moderation by counter conditioning

### IAT & self_reports

```{r}

results_for_meta_counterconditioning <- results_moderation_by_counterconditioning %>%
  rename(yi = cohens_d) %>%
  mutate(sei = (cohens_d_ci_upper - cohens_d_ci_lower)/(2*1.96)) %>%
  select(experiment, DV_type, yi, sei)

# iat
fit_moderation_counterconditioning_iat <- results_for_meta_counterconditioning %>%
  filter(str_detect(DV_type, "IAT_D2")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_iat,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-3.2, 3.8),
                at = c(-2.0, -1.0, 0, 1.0, 2.0))
text(-3.2, 5, "Moderation of IR by counterconditioning (IAT)", pos = 4)
text(3.8, 5, "d [95% CI]", pos = 2)

# IR
fit_moderation_counterconditioning_ir <- results_for_meta_counterconditioning %>%
  filter(str_detect(DV_type, "_IR_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_ir,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-3.2, 3.8),
                at = c(-2.0, -1.0, 0, 1.0, 2.0))
text(-3.2, 5, "Moderation of IR by counterconditioning (self-reported evaluations)", pos = 4)
text(3.8, 5, "d [95% CI]", pos = 2)

# OEC
fit_moderation_counterconditioning_oec <- results_for_meta_counterconditioning %>%
  filter(str_detect(DV_type, "_OEC_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_oec,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-3.2, 3.8),
                at = c(-2.0, -1.0, 0, 1.0, 2.0))
text(-3.2, 5, "Moderation of OEC by counterconditioning (self-reported evaluations)", pos = 4)
text(3.8, 5, "d [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_moderation_counterconditioning_iat, "models/fit_moderation_counterconditioning_iat.rds")
write_rds(fit_moderation_counterconditioning_ir, "models/fit_moderation_counterconditioning_ir.rds")
write_rds(fit_moderation_counterconditioning_oec, "models/fit_moderation_counterconditioning_oec.rds")

```

### Behavioral intentions

```{r}

fit_moderation_counterconditioning_ir <- data_reshaped_intentions_moderation_by_counterconditioning_ir %>%
  pivot_wider(names_from = experiment_condition,
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_acquisition_only,
         bi = brand_B_acquisition_only,
         ci = brand_A_acquisition_and_counterconditioning,
         di = brand_B_acquisition_and_counterconditioning,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_ir,
                addcred = TRUE,
                refline = 0,
                xlim = c(-5, 12),
                at = c(-2, 0, 2, 4, 6, 8))
text(-5, 5, "Moderation of IR by counterconditioning (behavioral intentions)", pos = 4)
text(12, 5, "OR [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_moderation_counterconditioning_ir, "models/fit_moderation_counterconditioning_ir.rds")

```

# Sensitivity meta-analyses

duplicate the above metas once finished, adding the following filters:

passed_performance_criterion_acquisition_training == TRUE &
passed_performance_criterion_acquisition_testing == TRUE &

# to do

## high priority

- study 7 participants could have extra training and testing data depending on performance. currently this is excluded, but it should be used. change data processing.

- study 7 processing file: add a note that indicates that the methodology file to let others know there is a difference in this file compared to others. need to check the completeness check issue (exclude partial but not excess), filter by max (block) instead of specific number 

- check if there are any issues with the data processing for the pass rate in studies 3 and 7 extinction testing - they're oddly low
- study 7 data processing needs attention for other unknown reasons: why are there multiple rows with the same unique id in the processed data? why do the Ns for the extinction and counterconditioning training and testing processed data equal the acquisition phase, when only one third of people should have done CC and extinction (each).

## medium priority

- demographics SUGGESTS THERE ARE REMAINING PROCESSING ISSUES - , na.rm = TRUE shouldn't be needed
- anova study 7 shouldn't require drop_na, why are there NAs after exclusions?
- handle between study differences
  - training and testing percent passes etc need code added to handle CC
- sensitivity meta analyses for training and testing exclusions




