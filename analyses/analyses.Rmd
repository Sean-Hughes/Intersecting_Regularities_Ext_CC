---
title: "IR, extinction, & counter conditioning"
subtitle: "Analyses & meta-analyses"
author: "Ian Hussey & Sean Hughes"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes 
    toc_float: yes
---

```{r include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE)
```

# Dependencies & functions

```{r}

# dependencies -----
library(tidyverse)
library(ggthemes)
library(knitr)
library(kableExtra)
library(broom)
library(effsize)
library(BayesFactor)
library(metafor)

# functions -----
# round p value using apa format
apa_p_value <- function(p){
  p_formatted <- ifelse(p >= 0.0001, paste("=", round(p, 4)),
                        ifelse(p < 0.0001, "< .0001", NA))
  p_formatted <- gsub(pattern = "0.", replacement = ".", x = p_formatted, fixed = TRUE)
  p_formatted
}

# calculate cohens d and return its output in tidy format - a helper function for analysis_workflow
tidy_cohens_d <- function(data){
  require(effsize)
  
  fit <- effsize::cohen.d(DV ~ IV, data = data)
  
  results <- tibble(cohens_d = fit$estimate,
                    cohens_d_ci_lower = fit$conf.int["lower"],
                    cohens_d_ci_upper = fit$conf.int["upper"])
  
  return(results)
}

# calculate cohens d and return its output in tidy format - a helper function for analysis_workflow
tidy_ttest_bf <- function(data){
  require(BayesFactor)
  
  fit <- data %>%
    ttestBF(formula = DV ~ IV, data = .)

  results <- data.frame(bf10 = extractBF(fit)$bf)
  return(results)
}


# full analysis workflow
# NB workflow returns mean_reference and mean_comparison, where reference is the first factor level and comparison is the next highest level.
analysis_workflow <- function(data){
  
  # frequentist t test
  results_t_test <- data %>%
    group_by(experiment, DV_type) %>%
    do(broom::tidy(t.test(DV ~ IV, data = .))) %>%
    ungroup() %>%
    rename(t = statistic,
           df = parameter,
           p = p.value,
           mean_reference = estimate1,
           mean_comaprison = estimate2)
  
  # cohens d
  results_cohens_d <- data %>%
    group_by(experiment, DV_type) %>%
    do(tidy_cohens_d(data = .)) %>%
    ungroup()
  
  # BF t test
  results_bf_t_test <- data %>%
    group_by(experiment, DV_type) %>%
    do(tidy_ttest_bf(data = .)) %>%
    ungroup()
  
  # combine
  results <- 
    full_join(results_t_test,
              results_cohens_d,
              by = c("experiment", "DV_type")) %>%
    full_join(results_bf_t_test,
              by = c("experiment", "DV_type")) %>%
    select(experiment, DV_type, 
           mean_reference, mean_comaprison, 
           t, df, p, cohens_d, cohens_d_ci_lower, cohens_d_ci_upper, bf10) %>%
    mutate(reportable_result = paste0("Reference group M = ", round(mean_reference, 2), ", comparison group M = ", round(mean_comaprison, 2), ", t(", round(df, 2), ") = ", round(t, 2), ", p ", apa_p_value(p), ", d = ", round(cohens_d, 2), ", 95% CI [", round(cohens_d_ci_lower, 2), ", ", round(cohens_d_ci_upper, 2), "], BF10 = ", round(bf10, 1)))
  
  return(results)
}

# add heterogeneity stats string for forest plot
add_heterogeneity_metrics_to_forest <- function(fit) {
  bquote(paste("RE Model (", tau^2, " = ", .(formatC(round(fit$tau2, 1))), 
               ", ", I^2, " = ", .(formatC(round(fit$I2, 1))),
               "%, ", H^2," = ", .(formatC(round(fit$H2, 1))), ")"))
}

```

# Data and exclusions

 for sensitivity analyses later:
passed_performance_criterion_acquisition_training == TRUE &
passed_performance_criterion_acquisition_testing == TRUE &

```{r}

data_processed <-
  bind_rows(
    read_csv("../data/Study 1/processed/data_processed.csv"),
    read_csv("../data/Study 2/processed/data_processed.csv"),
    read_csv("../data/Study 3/processed/data_processed.csv"),
    read_csv("../data/Study 4/processed/data_processed.csv"),
    read_csv("../data/Study 5/processed/data_processed.csv"),
    read_csv("../data/Study 6/processed/data_processed.csv"),
    read_csv("../data/Study 7/processed/data_processed.csv")
  ) %>%
  # exclusions
  filter(completeness_acquisition_training == "complete" &
           completeness_acquisition_testing == "complete" &
           (completeness_extinction_training == "complete" | is.na(completeness_extinction_training)) &
           (completeness_extinction_testing == "complete" | is.na(completeness_extinction_testing)) &
           (completeness_counterconditioning_training == "complete" | is.na(completeness_counterconditioning_training)) &
           (completeness_counterconditioning_testing == "complete" | is.na(completeness_counterconditioning_testing)) &
           complete_iat_data == "complete" &
           passed_iat_performance == TRUE) %>%
  # set factor levels for t test comparisons
  mutate(experiment_condition = fct_relevel(experiment_condition,
                                            "acquisition_only", 
                                            "acquisition_and_extinction",
                                            "acquisition_and_counterconditioning"),
         stimulus_identity_condition = fct_relevel(stimulus_identity_condition,
                                                   "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad",
                                                   "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good")) %>%
  
  # for testing
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_extinction") & 
           experiment %in% c(1,2,3,4,7))

```

# Analyses by study

## Was there an IR effect?

- by DV
- Differences between stimulus identity, using only the acquisition_only condition.

```{r}

results_basic_effect <- data_processed %>%
  filter(experiment_condition == "acquisition_only") %>%
  rename(IV = stimulus_identity_condition) %>%
  gather(DV_type, DV, c(self_reported_OEC_effect, self_reported_IR_effect, IAT_D2)) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  analysis_workflow(data = .)

results_basic_effect %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Was the IR moderated by intervention?

- by DV
- Differences between experiment conditions, after reverse scoring for stimulus identity.

```{r}

results_moderation_of_basic_effect <- data_processed %>%
  rename(IV = experiment_condition) %>%
  gather(DV_type, DV, c(self_reported_OEC_effect_controlling_stimulus_identity, 
                        self_reported_IR_effect_controlling_stimulus_identity, 
                        IAT_D2_controlling_stimulus_identity)) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  analysis_workflow(data = .)

results_moderation_of_basic_effect %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Meta-analyses

```{r}

results_for_meta_basic_effect <- results_basic_effect %>%
  rename(yi = cohens_d) %>%
  mutate(sei = (cohens_d_ci_upper - cohens_d_ci_lower)/(2*1.96)) %>%
  select(experiment, DV_type, yi, sei)

# iat
fit_basic_effect_iat <- results_for_meta_basic_effect %>%
  filter(str_detect(DV_type, "IAT_D2")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_iat,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                #xlim = c(-1.5, 1.7),
                #at = c(-0.5, -0.25, 0, 0.25, 0.5, 0.75, 1),
                mlab = add_heterogeneity_metrics_to_forest(fit_basic_effect_iat))
# text(-1.5, 10, "Study", pos = 4)
# text(1.7, 10, "ICC [95% CI]", pos = 2)

# IR
fit_basic_effect_ir <- results_for_meta_basic_effect %>%
  filter(str_detect(DV_type, "_IR_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_ir,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                #xlim = c(-1.5, 1.7),
                #at = c(-0.5, -0.25, 0, 0.25, 0.5, 0.75, 1),
                mlab = add_heterogeneity_metrics_to_forest(fit_basic_effect_ir))
# text(-1.5, 10, "Study", pos = 4)
# text(1.7, 10, "ICC [95% CI]", pos = 2)

# OEC
fit_basic_effect_oec <- results_for_meta_basic_effect %>%
  filter(str_detect(DV_type, "_OEC_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_oec,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                #xlim = c(-1.5, 1.7),
                #at = c(-0.5, -0.25, 0, 0.25, 0.5, 0.75, 1),
                mlab = add_heterogeneity_metrics_to_forest(fit_basic_effect_oec))
# text(-1.5, 10, "Study", pos = 4)
# text(1.7, 10, "ICC [95% CI]", pos = 2)

```


# to do

- handle between study differences
  - remove the for testing filter call in data processing!
- separate workflow for intentions (multinominal logistic)
- sensitivity meta analyses for training and testing exclusions
- add anova for study 7
- plot training and testing data
- separate reading in of data and exclusions, do demographics descriptives before exclusions







