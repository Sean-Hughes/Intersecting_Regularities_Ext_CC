---
title: "IR, extinction, & counter conditioning"
subtitle: "Analyses & meta-analyses"
author: "Ian Hussey & Sean Hughes"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes 
    toc_float: yes
---

```{r include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE)
```

.libPaths()


# Dependencies & functions

```{r}

# dependencies -----
library(tidyverse)
library(ggthemes)
library(knitr)
library(kableExtra)
library(broom)
library(effsize)
library(BayesFactor)
library(metafor)
library(ez)
library(schoRsch)
library(nnet)

# Ensures that the processed data folder exists
dir.create("models")

# functions -----
# round p value using apa format
apa_p_value <- function(p){
  p_formatted <- ifelse(p >= 0.0001, paste("=", round(p, 4)),
                        ifelse(p < 0.0001, "< .0001", NA))
  p_formatted <- gsub(pattern = "0.", replacement = ".", x = p_formatted, fixed = TRUE)
  p_formatted
}

# calculate cohens d and return its output in tidy format - a helper function for analysis_workflow
tidy_cohens_d <- function(data){
  require(effsize)
  
  fit <- effsize::cohen.d(DV ~ IV, data = data)
  
  results <- tibble(cohens_d = fit$estimate,
                    cohens_d_ci_lower = fit$conf.int["lower"],
                    cohens_d_ci_upper = fit$conf.int["upper"])
  
  return(results)
}

# calculate cohens d and return its output in tidy format - a helper function for analysis_workflow
tidy_ttest_bf <- function(data){
  require(BayesFactor)
  
  fit <- data %>%
    ttestBF(formula = DV ~ IV, data = .)

  results <- data.frame(bf10 = extractBF(fit)$bf)
  return(results)
}


# full analysis workflow
# NB workflow returns mean_reference and mean_comparison, where reference is the first factor level and comparison is the next highest level.
analysis_workflow <- function(data){
  
  # frequentist t test
  results_t_test <- data %>%
    group_by(experiment, DV_type) %>%
    do(broom::tidy(t.test(DV ~ IV, data = .))) %>%
    ungroup() %>%
    rename(t = statistic,
           df = parameter,
           p = p.value,
           mean_reference = estimate1,
           mean_comaprison = estimate2)

  # cohens d
  results_cohens_d <- data %>%
    group_by(experiment, DV_type) %>%
    do(tidy_cohens_d(data = .)) %>%
    ungroup()
  
  # BF t test
  results_bf_t_test <- data %>%
    group_by(experiment, DV_type) %>%
    do(tidy_ttest_bf(data = .)) %>%
    ungroup()
  
  # combine
  results <- 
    full_join(results_t_test,
              results_cohens_d,
              by = c("experiment", "DV_type")) %>%
    full_join(results_bf_t_test,
              by = c("experiment", "DV_type")) %>%
    select(experiment, DV_type, 
           mean_reference, mean_comaprison, 
           t, df, p, cohens_d, cohens_d_ci_lower, cohens_d_ci_upper, bf10) %>%
    mutate(reportable_result = paste0("Reference group M = ", round(mean_reference, 2), ", comparison group M = ", round(mean_comaprison, 2), ", t(", round(df, 2), ") = ", round(t, 2), ", p ", apa_p_value(p), ", d = ", round(cohens_d, 2), ", 95% CI [", round(cohens_d_ci_lower, 2), ", ", round(cohens_d_ci_upper, 2), "], BF10 = ", round(bf10, 1)))
  
  return(results)
}

# multinominal analysis
tidy_multinominal_analysis <- function(data) {
  
  require(nnet)
  
  # fit model
  fit <- multinom(DV ~ IV, 
                  data = data)
  
  # calculate p values
  z <- summary(fit)$coefficients/summary(fit)$standard.errors
  p <- (1 - pnorm(abs(z), 0, 1)) * 2
  
  pvalues <- p %>%
    as.data.frame() %>%
    rownames_to_column(var = "var") %>%
    rename(p = "IVcondition_2") %>%
    mutate(p = apa_p_value(p)) %>%
    select(p)
  
  # calc odds ratios and CIs
  coefficients <- as.data.frame(summary(fit)$coefficients) %>%
    rownames_to_column(var = "var") %>%
    rename(logOR = "IVcondition_2") %>%
    select(var, logOR)
  
  se <- as.data.frame(summary(fit)$standard.errors) %>%
    rownames_to_column(var = "var") %>%
    rename(logOR_se = "IVcondition_2") %>%
    select(logOR_se)
  
  # combine
  results <- bind_cols(coefficients, se) %>%
    mutate(OR = round(exp(logOR), 2),
           OR_ci_lwr = round(exp(logOR - logOR_se*1.96), 2),
           OR_ci_upr = round(exp(logOR + logOR_se*1.96), 2)) %>%
    bind_cols(pvalues) %>%
    rename(comparison_level = var)
  
  return(results)
}

# multinominal logistic regression workflow 
logistic_analysis_workflow <- function(data){
  require(nnet)
  
  results <- data %>%
    group_by(experiment, DV_type) %>%
    do(tidy_multinominal_analysis(data = .)) %>%
    ungroup() %>%
    mutate(reportable_result = paste0("OR = ", round(OR, 2), ", 95% CI [", round(OR_ci_lwr, 2), ", ", round(OR_ci_upr, 2), "], p ", apa_p_value(p)))
  
  return(results)
}

# add heterogeneity stats string for forest plot
add_heterogeneity_metrics_to_forest <- function(fit) {
  bquote(paste("RE Model (", tau^2, " = ", .(formatC(round(fit$tau2, 1))), 
               ", ", I^2, " = ", .(formatC(round(fit$I2, 1))),
               "%, ", H^2," = ", .(formatC(round(fit$H2, 1))), ")"))
}

```

# Data and exclusions

```{r}

# full data
data_processed <-
  bind_rows(
    read_csv("../data/Study 1/processed/data_processed.csv"),
    read_csv("../data/Study 2/processed/data_processed.csv"),
    read_csv("../data/Study 3/processed/data_processed.csv"),
    read_csv("../data/Study 4/processed/data_processed.csv"),
    read_csv("../data/Study 5/processed/data_processed.csv"),
    read_csv("../data/Study 6/processed/data_processed.csv"),
    read_csv("../data/Study 7/processed/data_processed.csv")
  ) %>%
  # set factor levels for t test comparisons
  mutate(experiment_condition = fct_relevel(experiment_condition,
                                            "acquisition_only", 
                                            "acquisition_and_extinction",
                                            "acquisition_and_counterconditioning"),
         stimulus_identity_condition = fct_relevel(stimulus_identity_condition,
                                                   "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad",
                                                   "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good")) %>%
  mutate(exclude = ifelse(completeness_acquisition_training == "complete" &
                            completeness_acquisition_testing == "complete" &
                            (completeness_extinction_training == "complete" | 
                               is.na(completeness_extinction_training)) &
                            (completeness_extinction_testing == "complete" | 
                               is.na(completeness_extinction_testing)) &
                            (completeness_counterconditioning_training == "complete" |
                               is.na(completeness_counterconditioning_training)) &
                            (completeness_counterconditioning_testing == "complete" |
                               is.na(completeness_counterconditioning_testing)) &
                            complete_iat_data == "complete" &
                            passed_iat_performance == TRUE,
                          FALSE, TRUE)) %>%
  
  ## move this to data processing??
  
  mutate(
    # recoding for the IR intentions data
    behavioral_intentions_IR = case_when(
      as.character(behavioral_intentions_IR) == "I would try Brand 2" ~ "brand_A",
      as.character(behavioral_intentions_IR) == "I would try Brand 4" ~ "brand_B",
      as.character(behavioral_intentions_IR) == "I would try Brands 2 and 4" ~ "both",
      as.character(behavioral_intentions_IR) == "I would try neither Brand" ~ "neither",
      as.character(behavioral_intentions_IR) == "I don't know" ~ "idontknow",
      TRUE ~ as.character(behavioral_intentions_IR)
    ),
    # recoding for the OEC intentions data
    behavioral_intentions_OEC = case_when(
      as.character(behavioral_intentions_OEC) == "I would try Brand 1" ~ "brand_A",
      as.character(behavioral_intentions_OEC) == "I would try Brand 3" ~ "brand_B",
      as.character(behavioral_intentions_OEC) == "I would try Brands 1 and 3" ~ "both",
      as.character(behavioral_intentions_OEC) == "I would try neither Brand" ~ "neither",
      as.character(behavioral_intentions_OEC) == "I don't know" ~ "idontknow",
      TRUE ~ as.character(behavioral_intentions_OEC)
    ),
    # reverse score
    behavioral_intentions_IR_controlling_stimulus_identity = case_when(
      stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" & 
        as.character(behavioral_intentions_IR) == "brand_A" ~ "brand_B",
      stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" & 
        as.character(behavioral_intentions_IR) == "brand_A" ~ "brand_A",
      stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" & 
        as.character(behavioral_intentions_IR) == "brand_B" ~ "brand_A",
      stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" & 
        as.character(behavioral_intentions_IR) == "brand_B" ~ "brand_B",
      TRUE ~ as.character(behavioral_intentions_IR)
    ),
    behavioral_intentions_OEC_controlling_stimulus_identity = case_when(
      stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" & 
        as.character(behavioral_intentions_OEC) == "brand_A" ~ "brand_B",
      stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" & 
        as.character(behavioral_intentions_OEC) == "brand_A" ~ "brand_A",
      stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" & 
        as.character(behavioral_intentions_OEC) == "brand_B" ~ "brand_A",
      stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" & 
        as.character(behavioral_intentions_OEC) == "brand_B" ~ "brand_B",
      TRUE ~ as.character(behavioral_intentions_OEC)
    )
  ) 



# exclusions
data_processed_after_exclusions <- data_processed %>%
  filter(exclude == FALSE)


```

# Demographics

, na.rm = TRUE shouldn't be needed, check data processing

why are there 49 participants in an unknown experiment?

```{r}

data_processed %>%
  group_by(experiment) %>%
  summarize(n = n(),
            age_mean = mean(age, na.rm = TRUE),
            age_sd = mean(age, na.rm = TRUE),
            excluded_n = sum(exclude, na.rm = TRUE),
            excluded_percent = mean(exclude*100, na.rm = TRUE)) %>%
  mutate_if(is.numeric, round, digits = 1)

```

# Training and testing mastery

## Percentage accuracy

```{r fig.height=10, fig.width=7}

results_training_and_testing_percent_accuracy <- data_processed_after_exclusions %>% 
  select(unique_id, experiment, 
         mean_correct_acquisition_training,         mean_correct_acquisition_testing, 
         mean_correct_extinction_training,          mean_correct_extinction_testing, 
         mean_correct_counterconditioning_training, mean_correct_counterconditioning_testing) %>%
  gather(phase, mean_correct, c(mean_correct_acquisition_training, mean_correct_acquisition_testing, 
                                mean_correct_extinction_training, mean_correct_extinction_testing, 
                                mean_correct_counterconditioning_training, mean_correct_counterconditioning_testing)) %>%
  distinct(unique_id, phase, .keep_all = TRUE) %>%
  drop_na() %>%
  mutate(phase = dplyr::recode(phase, 
                               "mean_correct_acquisition_training" = "Acquisition\ntraining",
                               "mean_correct_acquisition_testing" = "Acquisition\ntest",
                               "mean_correct_extinction_training" = "Extinction\ntraining",
                               "mean_correct_extinction_testing" = "Extinction\ntesting",
                               "mean_correct_counterconditioning_training" = "Counterconditioning\ntraining",
                               "mean_correct_counterconditioning_testing" = "Counterconditioning\ntesting")) %>%
  mutate(phase = as.factor(phase)) %>% 
  mutate(phase = fct_relevel(phase, "Acquisition\ntraining",
                                    "Acquisition\ntest",
                                    "Extinction\ntraining",
                                    "Extinction\ntesting",
                                    "Counterconditioning\ntraining",
                                    "Counterconditioning\ntesting")) %>%
  
  group_by(experiment, phase) %>% 
  dplyr::summarise(mean_accuracy = mean(mean_correct*100, na.rm = TRUE), 
                   sd_accuracy = sd(mean_correct*100, na.rm = TRUE)) %>%
  ungroup()

results_training_and_testing_percent_accuracy %>%
  mutate_if(is.numeric, round, digits = 0) %>%
  mutate(result = paste0(mean_accuracy, " (", sd_accuracy, ")")) %>%
  select(-mean_accuracy, -sd_accuracy) %>%
  spread(phase, result) %>%
  kable(knitr.kable.NA = "/", align = "c") %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) 
 
  
# ggplot(results_training_and_testing_percent_accuracy, aes(x = phase, y = mean_accuracy)) +
#   geom_bar(colour = "black", stat = "identity") + 
#   geom_errorbar(aes(ymin = mean_accuracy - sd_accuracy, ymax = mean_accuracy + sd_accuracy), 
#                 width = .2) + 
#   theme_classic() +
#   facet_wrap(~experiment, ncol = 1)

```

## Percentage pass

```{r fig.height=10, fig.width=7}

results_training_and_testing_percent_pass <- data_processed_after_exclusions %>% 
  select(unique_id, experiment, 
         passed_performance_criterion_acquisition_training,         passed_performance_criterion_acquisition_testing, 
         passed_performance_criterion_extinction_training,          passed_performance_criterion_extinction_testing, 
         passed_performance_criterion_counterconditioning_training, passed_performance_criterion_counterconditioning_testing) %>%
  gather(phase, passed_performance_criterion, c(passed_performance_criterion_acquisition_training,
                                                passed_performance_criterion_acquisition_testing, 
                                                passed_performance_criterion_extinction_training,
                                                passed_performance_criterion_extinction_testing, 
                                                passed_performance_criterion_counterconditioning_training,
                                                passed_performance_criterion_counterconditioning_testing)) %>%
  distinct(unique_id, phase, .keep_all = TRUE) %>%
  drop_na() %>%
  mutate(phase = dplyr::recode(phase, 
                            "passed_performance_criterion_acquisition_training" = "Acquisition\ntraining",
                            "passed_performance_criterion_acquisition_testing" = "Acquisition\ntest",
                            "passed_performance_criterion_extinction_training" = "Extinction\ntraining",
                            "passed_performance_criterion_extinction_testing" = "Extinction\ntesting",
                            "passed_performance_criterion_counterconditioning_training" = "Counterconditioning\ntraining",
                            "passed_performance_criterion_counterconditioning_testing" = "Counterconditioning\ntesting")) %>%
  
  mutate(phase = as.factor(phase)) %>% 
  mutate(phase = fct_relevel(phase, "Acquisition\ntraining",
                                    "Acquisition\ntest",
                                    "Extinction\ntraining",
                                    "Extinction\ntesting",
                                    "Counterconditioning\ntraining",
                                    "Counterconditioning\ntesting")) %>%
  
  
  
  group_by(experiment, phase) %>% 
  dplyr::summarise(percent_passed = mean(passed_performance_criterion*100, na.rm = TRUE)) %>%
  ungroup()

results_training_and_testing_percent_pass %>%
  mutate_if(is.numeric, round, digits = 0) %>%
  spread(phase, percent_passed) %>%
  kable(knitr.kable.NA = "/", align = "c") %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  
```

# Analyses by study

## Was there an IR effect?

### IAT & self_reports

- by DV
- Differences between stimulus identity, using only the acquisition_only condition.

```{r}

results_basic_effect_iat_selfreports <- data_processed_after_exclusions %>%
  filter(experiment_condition == "acquisition_only") %>%
  rename(IV = stimulus_identity_condition) %>%
  gather(DV_type, DV, c(self_reported_OEC_effect, self_reported_IR_effect, IAT_D2)) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  analysis_workflow(data = .)

results_basic_effect_iat_selfreports %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

### Behavioral intentions

```{r}

results_basic_effect_intentions <- data_processed_after_exclusions %>%
  filter(experiment_condition == "acquisition_only") %>%
  # recode the IV to work with the generic workflow
  mutate(
    stimulus_identity_condition = case_when(stimulus_identity_condition == "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" ~ "condition_1",
                                            stimulus_identity_condition == "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" ~ "condition_2"),
    stimulus_identity_condition = fct_relevel(stimulus_identity_condition, "condition_1", "condition_2")
  ) %>%
  # rename to work with the generic workflow
  rename(IV = stimulus_identity_condition) %>%
  gather(DV_type, DV, c(behavioral_intentions_IR, behavioral_intentions_OEC)) %>%
  # set a reference category for the multinominal logistic regression
  mutate(DV = relevel(as.factor(DV), ref = "brand_A")) %>%
  select(experiment, DV_type, DV, IV) %>%
  logistic_analysis_workflow()

results_basic_effect_intentions %>%
  # return results for only the comparison of interest
  filter(comparison_level == "brand_B") %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Was the IR moderated by extinction?

### IAT & self_reports

- by DV
- Differences between experiment conditions, after reverse scoring for stimulus identity.

```{r}

results_moderation_by_extinction <- data_processed_after_exclusions %>%
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_extinction") & 
           experiment %in% c(1, 2, 3, 4, 7)) %>%
  rename(IV = experiment_condition) %>%
  mutate(IV = fct_relevel(IV, "acquisition_and_extinction", "acquisition_only")) %>%
  gather(DV_type, DV, c(self_reported_OEC_effect_controlling_stimulus_identity, 
                        self_reported_IR_effect_controlling_stimulus_identity, 
                        IAT_D2_controlling_stimulus_identity)) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  analysis_workflow(data = .)

results_moderation_by_extinction %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

### Behavioral intentions

```{r}

results_moderation_by_extinction_intentions <- data_processed_after_exclusions %>%
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_extinction") & 
           experiment %in% c(1, 2, 3, 4, 7)) %>%
  # recode the IV to work with the generic workflow
  mutate(
    experiment_condition = case_when(experiment_condition == "acquisition_only" ~ "condition_1",
                                     experiment_condition == "acquisition_and_extinction" ~ "condition_2"),
    experiment_condition = fct_relevel(experiment_condition, "condition_1", "condition_2")
  ) %>%
  # rename to work with the generic workflow
  rename(IV = experiment_condition) %>%
  gather(DV_type, DV, c(behavioral_intentions_IR_controlling_stimulus_identity,
                        behavioral_intentions_OEC_controlling_stimulus_identity)) %>%
  # set a reference category for the multinominal logistic regression
  mutate(DV = relevel(as.factor(DV), ref = "brand_A")) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  logistic_analysis_workflow()

results_moderation_by_extinction_intentions %>%
  # return results for only the comparison of interest
  filter(comparison_level == "brand_B") %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Was the IR moderated by counter conditioning?

### IAT & self_reports

- by DV
- Differences between experiment conditions, after reverse scoring for stimulus identity.

```{r}

results_moderation_by_counterconditioning <- data_processed_after_exclusions %>%
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_counterconditioning") & 
           experiment %in% c(5, 6, 7)) %>%
  rename(IV = experiment_condition) %>%
  mutate(IV = fct_relevel(IV, "acquisition_and_counterconditioning", "acquisition_only")) %>%
  gather(DV_type, DV, c(self_reported_OEC_effect_controlling_stimulus_identity, 
                        self_reported_IR_effect_controlling_stimulus_identity, 
                        IAT_D2_controlling_stimulus_identity)) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  analysis_workflow(data = .)

results_moderation_by_counterconditioning %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

### Behavioral intentions

```{r}

results_moderation_by_counterconditioning_intentions <- data_processed_after_exclusions %>%
  filter(experiment_condition %in% c("acquisition_only", "acquisition_and_counterconditioning") & 
           experiment %in% c(5, 6, 7)) %>%
  # recode the IV to work with the generic workflow
  mutate(
    experiment_condition = case_when(experiment_condition == "acquisition_only" ~ "condition_1",
                                     experiment_condition == "acquisition_and_counterconditioning" ~ "condition_2"),
    experiment_condition = fct_relevel(experiment_condition, "condition_1", "condition_2")
  ) %>%
  # rename to work with the generic workflow
  rename(IV = experiment_condition) %>%
  gather(DV_type, DV, c(behavioral_intentions_IR_controlling_stimulus_identity, 
                        behavioral_intentions_OEC_controlling_stimulus_identity)) %>%
  # set a reference category for the multinominal logistic regression
  mutate(DV = relevel(as.factor(DV), ref = "brand_A")) %>%
  select(experiment, DV_type, DV, IV) %>%
  drop_na() %>%
  logistic_analysis_workflow()

results_moderation_by_counterconditioning_intentions %>%
  # return results for only the comparison of interest
  filter(comparison_level == "brand_B") %>%
  select(experiment, DV_type, reportable_result) %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Study 7 ANOVA

drop_na SHOULDN'T BE NEEDED ??

```{r}

data_study_7 <- data_processed_after_exclusions %>%
  filter(experiment == 7) %>%
  select(unique_id,
         self_reported_IR_effect_controlling_stimulus_identity,
         self_reported_OEC_effect_controlling_stimulus_identity,
         IAT_D2_controlling_stimulus_identity,
         experiment_condition) %>%
  drop_na()

# IAT
fit_study_7_iat <- ez::ezANOVA(data     = data_study_7,
                               dv       = IAT_D2_controlling_stimulus_identity,
                               between  = experiment_condition,
                               wid      = unique_id,
                               type     = 3,
                               detailed = TRUE)

 
  
# IR
fit_study_7_ir <- ez::ezANOVA(data     = data_study_7,
                              dv       = self_reported_IR_effect_controlling_stimulus_identity,
                              between  = experiment_condition,
                              wid      = unique_id,
                              type     = 3,
                              detailed = TRUE)

# OEC
fit_study_7_oec <- ez::ezANOVA(data     = data_study_7,
                               dv       = self_reported_OEC_effect_controlling_stimulus_identity,
                               between  = experiment_condition,
                               wid      = unique_id,
                               type     = 3,
                               detailed = TRUE)

# combine results
results_study_7 <- 
  bind_rows(anova_out(fit_study_7_iat, 
                      etasq = "partial", 
                      print = FALSE)$`--- FORMATTED RESULTS ------------------------------------` %>%
              mutate(DV = "IAT"),
            anova_out(fit_study_7_ir, 
                      etasq = "partial", 
                      print = FALSE)$`--- FORMATTED RESULTS ------------------------------------` %>%
              mutate(DV = "IR"),
            anova_out(fit_study_7_oec, 
                      etasq = "partial", 
                      print = FALSE)$`--- FORMATTED RESULTS ------------------------------------` %>%
              mutate(DV = "OEC")) %>%
  filter(Effect == "experiment_condition") %>%
  select(DV, Text)

results_study_7 %>%
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Meta-analyses

## Basic effect

### IAT & self_reports

```{r}

results_for_meta_basic_effect_iat_selfreports <- results_basic_effect_iat_selfreports %>%
  rename(yi = cohens_d) %>%
  mutate(sei = (cohens_d_ci_upper - cohens_d_ci_lower)/(2*1.96)) %>%
  select(experiment, DV_type, yi, sei)

# iat
fit_basic_effect_iat <- results_for_meta_basic_effect_iat_selfreports %>%
  filter(str_detect(DV_type, "IAT_D2")) %>%
  rma(yi   = yi,
      sei  = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_iat,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-1.5, 4),
                at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
text(-1.5, 9, "IAT (IR)", pos = 4)
text(4, 9, "d [95% CI]", pos = 2)

# IR
fit_basic_effect_ir <- results_for_meta_basic_effect_iat_selfreports %>%
  filter(str_detect(DV_type, "_IR_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_ir,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-1.5, 4),
                at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
text(-1.5, 9, "Self-reported evaluations (IR)", pos = 4)
text(4, 9, "d [95% CI]", pos = 2)

# OEC
fit_basic_effect_oec <- results_for_meta_basic_effect_iat_selfreports %>%
  filter(str_detect(DV_type, "_OEC_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_oec,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-1.5, 4),
                at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
text(-1.5, 9, "Self-reported evaluations (OEC)", pos = 4)
text(4, 9, "d [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_basic_effect_iat, "models/fit_basic_effect_iat.rds")
write_rds(fit_basic_effect_ir, "models/fit_basic_effect_ir.rds")
write_rds(fit_basic_effect_oec, "models/fit_basic_effect_oec.rds")

```

### Behavioral intentions

```{r}

results_for_meta_basic_effect_intentions <- results_basic_effect_intentions %>%
  # return results for only the comparison of interest
  filter(comparison_level == "brand_B") %>%
  rename(yi = logOR, 
         sei = logOR_se) %>%
  select(experiment, DV_type, yi, sei)

# ir
fit_basic_effect_intentions_ir <- results_for_meta_basic_effect_intentions %>%
  filter(str_detect(DV_type, "behavioral_intentions_IR")) %>%
  rma(yi   = yi,
      sei  = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_intentions_ir,
                #transf = exp,
                xlab = "OR",
                addcred = TRUE,
                refline = 1)
                # xlim = c(-1.5, 4),
                # at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
# text(-1.5, 9, "Behavioral intentions (IR)", pos = 4)
# text(4, 9, "OR [95% CI]", pos = 2)

# oec
fit_basic_effect_intentions_oec <- results_for_meta_basic_effect_intentions %>%
  filter(str_detect(DV_type, "behavioral_intentions_OEC")) %>%
  rma(yi   = yi,
      sei  = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_basic_effect_intentions_oec,
                #transf = exp,
                xlab = "OR",
                addcred = TRUE,
                refline = 1)
                # xlim = c(-1.5, 4),
                # at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
# text(-1.5, 9, "Behavioral intentions (OEC)", pos = 4)
# text(4, 9, "OR [95% CI]", pos = 2)

```

## Moderation by extinction

### IAT & self_reports

```{r}

results_for_meta_extinction <- results_moderation_by_extinction %>%
  rename(yi = cohens_d) %>%
  mutate(sei = (cohens_d_ci_upper - cohens_d_ci_lower)/(2*1.96)) %>%
  select(experiment, DV_type, yi, sei)

# iat
fit_moderation_extinction_iat <- results_for_meta_extinction %>%
  filter(str_detect(DV_type, "IAT_D2")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_iat,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-2.25, 2.25),
                at = c(-1.5, -1.0, -0.5, 0, 0.5, 1.0))
text(-2.25, 7, "IAT (IR)", pos = 4)
text(2.25, 7, "d [95% CI]", pos = 2)

# IR
fit_moderation_extinction_ir <- results_for_meta_extinction %>%
  filter(str_detect(DV_type, "_IR_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_ir,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-2.25, 2.25),
                at = c(-1.5, -1.0, -0.5, 0, 0.5, 1.0))
text(-2.25, 7, "Self-reported evaluations (IR)", pos = 4)
text(2.25, 7, "d [95% CI]", pos = 2)

# OEC
fit_moderation_extinction_oec <- results_for_meta_extinction %>%
  filter(str_detect(DV_type, "_OEC_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_oec,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-2.25, 2.25),
                at = c(-1.5, -1.0, -0.5, 0, 0.5, 1.0))
text(-2.25, 7, "Self-reported evaluations (OEC)", pos = 4)
text(2.25, 7, "d [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_moderation_extinction_iat, "models/fit_moderation_extinction_iat.rds")
write_rds(fit_moderation_extinction_ir, "models/fit_moderation_extinction_ir.rds")
write_rds(fit_moderation_extinction_oec, "models/fit_moderation_extinction_oec.rds")

```

### Behavioral intentions

```{r}

results_for_meta_extinction_intentions <- results_moderation_by_extinction_intentions %>%
  # return results for only the comparison of interest
  filter(comparison_level == "brand_B") %>%
  rename(yi = logOR, 
         sei = logOR_se) %>%
  select(experiment, DV_type, yi, sei)

# ir
fit_moderation_extinction_ir <- results_for_meta_extinction_intentions %>%
  filter(str_detect(DV_type, "behavioral_intentions_IR")) %>%
  rma(yi   = yi,
      sei  = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_ir,
                transf = exp,
                xlab = "OR",
                addcred = TRUE,
                refline = 1)
                # xlim = c(-1.5, 4),
                # at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
# text(-1.5, 9, "Behavioral intentions (IR)", pos = 4)
# text(4, 9, "OR [95% CI]", pos = 2)

# oec
fit_moderation_extinction_oec <- results_for_meta_extinction_intentions %>%
  filter(str_detect(DV_type, "behavioral_intentions_OEC")) %>%
  rma(yi   = yi,
      sei  = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_extinction_oec,
                transf = exp,
                xlab = "OR",
                addcred = TRUE,
                refline = 1)
                # xlim = c(-1.5, 4),
                # at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
# text(-1.5, 9, "Behavioral intentions (OEC)", pos = 4)
# text(4, 9, "OR [95% CI]", pos = 2)

```

## Moderation by counter conditioning

### IAT & self_reports

```{r}

results_for_meta_counterconditioning <- results_moderation_by_counterconditioning %>%
  rename(yi = cohens_d) %>%
  mutate(sei = (cohens_d_ci_upper - cohens_d_ci_lower)/(2*1.96)) %>%
  select(experiment, DV_type, yi, sei)

# iat
fit_moderation_counterconditioning_iat <- results_for_meta_counterconditioning %>%
  filter(str_detect(DV_type, "IAT_D2")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_iat,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-3.2, 3.8),
                at = c(-2.0, -1.0, 0, 1.0, 2.0))
text(-3.2, 5, "IAT (IR)", pos = 4)
text(3.8, 5, "d [95% CI]", pos = 2)

# IR
fit_moderation_counterconditioning_ir <- results_for_meta_counterconditioning %>%
  filter(str_detect(DV_type, "_IR_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_ir,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-3.2, 3.8),
                at = c(-2.0, -1.0, 0, 1.0, 2.0))
text(-3.2, 5, "Self-reported evaluations (IR)", pos = 4)
text(3.8, 5, "d [95% CI]", pos = 2)

# OEC
fit_moderation_counterconditioning_oec <- results_for_meta_counterconditioning %>%
  filter(str_detect(DV_type, "_OEC_")) %>%
  rma(yi = yi,
      sei = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_oec,
                xlab = "Cohen's d",
                addcred = TRUE,
                refline = 0,
                xlim = c(-3.2, 3.8),
                at = c(-2.0, -1.0, 0, 1.0, 2.0))
text(-3.2, 5, "Self-reported evaluations (OEC)", pos = 4)
text(3.8, 5, "d [95% CI]", pos = 2)

# save model fits for making pdf plots for publication
write_rds(fit_moderation_counterconditioning_iat, "models/fit_moderation_counterconditioning_iat.rds")
write_rds(fit_moderation_counterconditioning_ir, "models/fit_moderation_counterconditioning_ir.rds")
write_rds(fit_moderation_counterconditioning_oec, "models/fit_moderation_counterconditioning_oec.rds")

```

### Behavioral intentions

```{r}

results_for_meta_counterconditioning_intentions <- results_moderation_by_counterconditioning_intentions %>%
  # return results for only the comparison of interest
  filter(comparison_level == "brand_B") %>%
  rename(yi = logOR, 
         sei = logOR_se) %>%
  select(experiment, DV_type, yi, sei)

# ir
fit_moderation_counterconditioning_ir <- results_for_meta_counterconditioning_intentions %>%
  filter(str_detect(DV_type, "behavioral_intentions_IR")) %>%
  rma(yi   = yi,
      sei  = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_ir,
                transf = exp,
                xlab = "OR",
                addcred = TRUE,
                refline = 1)
                # xlim = c(-1.5, 4),
                # at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
# text(-1.5, 9, "Behavioral intentions (IR)", pos = 4)
# text(4, 9, "OR [95% CI]", pos = 2)

# oec
fit_moderation_counterconditioning_oec <- results_for_meta_counterconditioning_intentions %>%
  filter(str_detect(DV_type, "behavioral_intentions_OEC")) %>%
  rma(yi   = yi,
      sei  = sei,
      data = .,
      slab = experiment)

metafor::forest(fit_moderation_counterconditioning_oec,
                transf = exp,
                xlab = "OR",
                addcred = TRUE,
                refline = 1)
                # xlim = c(-1.5, 4),
                # at = c(-0.5, 0, 0.5, 1.0, 1.5, 2.0, 2.5))
# text(-1.5, 9, "Behavioral intentions (OEC)", pos = 4)
# text(4, 9, "OR [95% CI]", pos = 2)

```

## alternative to multinominal

instead of multinomial logistics, which dont seem to be working right now, we could just pull out the brand a and b responses and calculate odds ratios? 

### IR basic effect

```{r}

data_processed_after_exclusions %>%
  filter(experiment_condition == c("acquisition_only")) %>% 
  count(experiment, stimulus_identity_condition, behavioral_intentions_IR) %>%
  spread(behavioral_intentions_IR, n)

```

```{r}

# p values by experiment

library(epitools)

reshaped <- data_processed_after_exclusions %>%
  filter(experiment_condition == c("acquisition_only") & 
           behavioral_intentions_IR %in% c("brand_A", "brand_B")) %>% 
  count(experiment, stimulus_identity_condition, behavioral_intentions_IR) %>%
  spread(behavioral_intentions_IR, n) %>%
  # Haldane-Anscombe correction
  group_by(experiment) %>%
  mutate(count_zero = as.logical(max(c(is.na(brand_A), is.na(brand_B))))) %>%
  ungroup() %>%
  mutate(brand_A = ifelse(count_zero, brand_A+0.5, brand_A),
         brand_A = ifelse(is.na(brand_A), 0.5, brand_A),
         brand_B = ifelse(count_zero, brand_B+0.5, brand_B),
         brand_B = ifelse(is.na(brand_B), 0.5, brand_B)) %>%
  select(experiment, stimulus_identity_condition, brand_A, brand_B)

# this could also be reshaped for meta anlaysis so that study 3 is included.


  
temp_study_1 <- reshaped %>%
  filter(experiment == 3) %>%
  select(brand_A, brand_B) %>%
  as.matrix() %>%
  epitools::epitab(x = .)

temp_study_1$tab %>%
  as.data.frame() %>%
  drop_na() %>%
  select(OR = oddsratio, 
         OR_ci_lower = lower,
         OR_ci_upper = upper,
         p = p.value)

```


```{r}

data_processed_after_exclusions %>%
  filter(experiment_condition == c("acquisition_only")) %>% 
  count(experiment, stimulus_identity_condition, behavioral_intentions_IR) %>%
  spread(behavioral_intentions_IR, n)

data_processed_after_exclusions %>%
  filter(experiment_condition == c("acquisition_only")) %>% 
  count(experiment, stimulus_identity_condition, behavioral_intentions_IR) %>%
  spread(behavioral_intentions_IR, n) %>%
  select(experiment, stimulus_identity_condition, brand_A, brand_B) %>%
  mutate(stimulus_identity_condition = recode(stimulus_identity_condition, 
                                              "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" = "condition_A",
                                              "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" = "condition_B")) %>%
  pivot_wider(names_from = stimulus_identity_condition, 
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_condition_A,
         bi = brand_A_condition_B,
         ci = brand_B_condition_A,
         di = brand_B_condition_B,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment) %>%
  forest(refline = 0)

```

### OEC basic effect

```{r}

data_processed_after_exclusions %>%
  filter(experiment_condition == c("acquisition_only")) %>% 
  count(experiment, stimulus_identity_condition, behavioral_intentions_OEC) %>%
  spread(behavioral_intentions_OEC, n)

data_processed_after_exclusions %>%
  filter(experiment_condition == c("acquisition_only")) %>% 
  count(experiment, stimulus_identity_condition, behavioral_intentions_OEC) %>%
  spread(behavioral_intentions_OEC, n) %>%
  select(experiment, stimulus_identity_condition, brand_A, brand_B) %>%
  mutate(stimulus_identity_condition = recode(stimulus_identity_condition, 
                                              "Outcome_1_Target_1_Good_Outcome_2_Target_2_Bad" = "condition_A",
                                              "Outcome_1_Target_1_Bad_Outcome_2_Target_2_Good" = "condition_B")) %>%
  pivot_wider(names_from = stimulus_identity_condition, 
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_condition_A,
         bi = brand_A_condition_B,
         ci = brand_B_condition_A,
         di = brand_B_condition_B,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment) %>%
  forest(refline = 0)

```

### IR moderation by extinction

```{r}

data_processed_after_exclusions %>%
  filter(experiment %in% c(1, 2, 3, 4, 7) & 
           experiment_condition %in% c("acquisition_only", "acquisition_and_extinction")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_IR_controlling_stimulus_identity) %>%
  spread(behavioral_intentions_IR_controlling_stimulus_identity, n)

data_processed_after_exclusions %>%
  filter(experiment %in% c(1, 2, 3, 4, 7) & 
           experiment_condition %in% c("acquisition_only", "acquisition_and_extinction")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_IR_controlling_stimulus_identity) %>%
  spread(behavioral_intentions_IR_controlling_stimulus_identity, n) %>%
  select(experiment, experiment_condition, brand_A, brand_B) %>%
  pivot_wider(names_from = experiment_condition, 
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_acquisition_and_extinction,
         bi = brand_A_acquisition_only,
         ci = brand_B_acquisition_and_extinction,
         di = brand_B_acquisition_only,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment) %>%
  forest(refline = 0)

```

### OEC moderation by extinction

```{r}

data_processed_after_exclusions %>%
  filter(experiment %in% c(1, 2, 3, 4, 7) & 
           experiment_condition %in% c("acquisition_only", "acquisition_and_extinction")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_OEC_controlling_stimulus_identity) %>%
  spread(behavioral_intentions_OEC_controlling_stimulus_identity, n)

data_processed_after_exclusions %>%
  filter(experiment %in% c(1, 2, 3, 4, 7) & 
           experiment_condition %in% c("acquisition_only", "acquisition_and_extinction")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_OEC_controlling_stimulus_identity) %>%
  spread(behavioral_intentions_OEC_controlling_stimulus_identity, n) %>%
  select(experiment, experiment_condition, brand_A, brand_B) %>%
  pivot_wider(names_from = experiment_condition, 
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_acquisition_and_extinction,
         bi = brand_A_acquisition_only,
         ci = brand_B_acquisition_and_extinction,
         di = brand_B_acquisition_only,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment) %>%
  forest(refline = 0)

```

### IR moderation by counterconditioning

```{r}

data_processed_after_exclusions %>%
  filter(experiment %in% c(5, 6, 7) & 
           experiment_condition %in% c("acquisition_only", "acquisition_and_counterconditioning")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_IR_controlling_stimulus_identity) %>%
  spread(behavioral_intentions_IR_controlling_stimulus_identity, n)

data_processed_after_exclusions %>%
  filter(experiment %in% c(5, 6, 7) & 
           experiment_condition %in% c("acquisition_only", "acquisition_and_counterconditioning")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_IR_controlling_stimulus_identity) %>%
  spread(behavioral_intentions_IR_controlling_stimulus_identity, n) %>%
  select(experiment, experiment_condition, brand_A, brand_B) %>%
  pivot_wider(names_from = experiment_condition, 
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_acquisition_and_counterconditioning,
         bi = brand_A_acquisition_only,
         ci = brand_B_acquisition_and_counterconditioning,
         di = brand_B_acquisition_only,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment) %>%
  forest(refline = 0)

```

### OEC moderation by counterconditioning

```{r}

data_processed_after_exclusions %>%
  filter(experiment %in% c(5, 6, 7) & 
           experiment_condition %in% c("acquisition_only", "acquisition_and_counterconditioning")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_OEC_controlling_stimulus_identity) %>%
  spread(behavioral_intentions_OEC_controlling_stimulus_identity, n)

data_processed_after_exclusions %>%
  filter(experiment %in% c(5, 6, 7) & 
           experiment_condition %in% c("acquisition_only", "acquisition_and_counterconditioning")) %>% 
  count(experiment, experiment_condition, behavioral_intentions_OEC_controlling_stimulus_identity) %>%
  spread(behavioral_intentions_OEC_controlling_stimulus_identity, n) %>%
  select(experiment, experiment_condition, brand_A, brand_B) %>%
  pivot_wider(names_from = experiment_condition, 
              values_from = c(brand_A, brand_B)) %>%
  escalc(measure = "OR",
         ai = brand_A_acquisition_and_counterconditioning,
         bi = brand_A_acquisition_only,
         ci = brand_B_acquisition_and_counterconditioning,
         di = brand_B_acquisition_only,
         data = .) %>%
  rma(yi   = yi,
      vi   = vi,
      data = .,
      slab = experiment) %>%
  forest(refline = 0)

```

# Sensitivity meta-analyses

duplicate the above metas once finsihed, adding the following filters:

passed_performance_criterion_acquisition_training == TRUE &
passed_performance_criterion_acquisition_testing == TRUE &

# to do

## high priority

- study 7 participants could have extra training and testing data depending on performance. currently this is excluded, but it should be used. change data processing.
- check if there are any issues with the data processing for the pass rate in studies 3 and 7 extinction testing - they're oddly low
- study 7 data processing needs attention for other unknown reasons: why are there multiple rows with the same unique id in the processed data? why do the Ns for the extinction and counterconditioning training and testing processed data equal the acquisition phase, when only one third of people should have done CC and extinction (each).
- workflow for intentions (multinominal logistic)
  - results look possibly off, check workflow. CIs are not congruent with p values

## medium priority

- in analyses of individual studies, write full results to disk in each case.
- demographics SUGGESTS THERE ARE REMAINING PROCESSING ISSUES - , na.rm = TRUE shouldn't be needed
- anova study 7 shouldn't require drop_na, why are there NAs after exclusions?
- handle between study differences
  - training and testing percent passes etc need code added to handle CC
- sensitivity meta analyses for training and testing exclusions




